#!/usr/bin/env python3
"""
üéØ XVL (X-Ray Vision Lab) - Production Inference Pipeline
–ì–ª–∞–≤–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏.

–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:
  python run.py predict --image path/to/image.jpg        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
  python run.py predict --dir path/to/images/           # –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
  python run.py demo --count 5                         # –î–µ–º–æ —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –¥–∞–Ω–Ω—ã—Ö
  python run.py web                                     # –ó–∞–ø—É—Å–∫ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
"""

import argparse
import sys
import logging
from pathlib import Path
from typing import Optional, List
import warnings
warnings.filterwarnings('ignore')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–∏ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π –ø—Ä–æ–µ–∫—Ç–∞
sys.path.insert(0, str(Path(__file__).parent))

# –ò–º–ø–æ—Ä—Ç –Ω–∞—à–∏—Ö –º–æ–¥—É–ª–µ–π
from src.utils.logging_config import setup_logging
from src.inference.predictor import XVLPredictor, PredictionResult
from src.generators import DemoDataGenerator
from src.utils.ex—Åeptions import XVLBaseException, ModelLoadError, DataGenerationError

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = logging.getLogger(__name__)

class XVLCLI:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ XVL"""

    def __init__(self):
        self.predictor = None
        self.log_dir = None

    def setup_environment(self, verbose: bool = False):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        log_level = logging.DEBUG if verbose else logging.INFO
        self.log_dir = setup_logging(
            experiment_name="inference_run",
            log_level=log_level
        )
        logger.info("=" * 60)
        logger.info("XVL Inference Pipeline initialized")
        logger.info("=" * 60)

    def load_model(self, model_repo: str = None, device: str = None):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å Hugging Face Hub"""
        try:
            logger.info(f"Loading model from Hugging Face Hub...")

            # –ï—Å–ª–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π
            if not model_repo:
                model_repo = "yourusername/xvl-weld-defect-detection"  # ‚Üê –ó–ê–ú–ï–ù–ò–¢–ï –Ω–∞ –≤–∞—à —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
                logger.info(f"Using default model repository: {model_repo}")

            self.predictor = XVLPredictor(
                model_repo=model_repo,
                device=device
            )

            logger.info("‚úÖ Model loaded successfully")
            logger.info(f"   Device: {self.predictor.device}")
            logger.info(f"   Classes: {list(self.predictor.class_names.values())}")

        except Exception as e:
            logger.error(f"Failed to load model: {str(e)}")
            raise ModelLoadError(
                f"Cannot load model from {model_repo}",
                details={"error": str(e), "repo": model_repo}
            )

    def predict_image(self, image_path: str, output_dir: Optional[str] = None) -> PredictionResult:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        if not self.predictor:
            self.load_model()

        image_path = Path(image_path)
        if not image_path.exists():
            raise FileNotFoundError(f"Image not found: {image_path}")

        logger.info(f"Processing image: {image_path.name}")

        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        result = self.predictor.predict(str(image_path))

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if output_dir:
            save_path = self.predictor.save_result(result, output_dir)
            logger.info(f"Results saved to: {save_path}")

        # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        defects_found = len(result.detections)
        logger.info(f"Found {defects_found} defect(s)")

        if defects_found > 0:
            for det in result.detections:
                logger.info(f"   - {det['class']}: {det['confidence']:.1%} "
                          f"at [{det['bbox'][0]:.0f}, {det['bbox'][1]:.0f}, "
                          f"{det['bbox'][2]:.0f}, {det['bbox'][3]:.0f}]")

        return result

    def predict_directory(self, dir_path: str, output_dir: str,
                         batch_size: int = 8) -> List[PredictionResult]:
        """–ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        if not self.predictor:
            self.load_model()

        dir_path = Path(dir_path)
        if not dir_path.exists() or not dir_path.is_dir():
            raise FileNotFoundError(f"Directory not found: {dir_path}")

        # –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
        image_files = [
            f for f in dir_path.iterdir()
            if f.suffix.lower() in image_extensions
        ]

        if not image_files:
            raise DataGenerationError(f"No images found in {dir_path}")

        logger.info(f"Found {len(image_files)} images in {dir_path}")

        # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        results = []
        for i, img_path in enumerate(image_files):
            try:
                logger.info(f"[{i+1}/{len(image_files)}] Processing {img_path.name}")
                result = self.predict_image(str(img_path), str(output_path))
                results.append(result)
            except Exception as e:
                logger.error(f"Failed to process {img_path.name}: {str(e)}")
                continue

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç
        self._generate_summary_report(results, output_path)

        return results

    def run_demo(self, count: int = 5, output_dir: str = "demo_results"):
        """–ó–∞–ø—É—Å–∫ –¥–µ–º–æ —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        logger.info(f"Starting demo mode with {count} generated images")

        # –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–µ–º–æ-–¥–∞–Ω–Ω—ã—Ö
        generator = DemoDataGenerator()

        # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –µ—â—ë –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞
        if not self.predictor:
            self.load_model()

        for i in range(count):
            try:
                logger.info(f"Generating demo image {i+1}/{count}...")

                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
                image, true_annotations = generator.generate()

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                input_path = output_path / f"demo_{i:03d}_input.jpg"
                image.save(input_path)

                # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                result = self.predictor.predict(str(input_path))

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                result_path = output_path / f"demo_{i:03d}_result.jpg"
                result.annotated_image.save(result_path)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                metadata = {
                    "image": f"demo_{i:03d}_input.jpg",
                    "true_defects": len(true_annotations),
                    "detected_defects": len(result.detections),
                    "defects": [
                        {
                            "class": det["class"],
                            "confidence": float(det["confidence"]),
                            "bbox": [float(c) for c in det["bbox"]]
                        }
                        for det in result.detections
                    ]
                }

                # –ú–æ–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ JSON
                import json
                metadata_path = output_path / f"demo_{i:03d}_metadata.json"
                with open(metadata_path, 'w') as f:
                    json.dump(metadata, f, indent=2)

                logger.info(f"  ‚Üí True defects: {len(true_annotations)}, "
                          f"Detected: {len(result.detections)}")

            except Exception as e:
                logger.error(f"Failed to generate demo {i+1}: {str(e)}")
                continue

        logger.info(f"‚úÖ Demo completed. Results saved to: {output_path}")
        logger.info(f"   To view: open {output_path}/demo_*.jpg")

    def _generate_summary_report(self, results: List[PredictionResult], output_dir: Path):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –ø–æ –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ"""
        if not results:
            return

        total_images = len(results)
        total_defects = sum(len(r.detections) for r in results)
        defect_by_class = {}

        for result in results:
            for det in result.detections:
                class_name = det["class"]
                defect_by_class[class_name] = defect_by_class.get(class_name, 0) + 1

        # –°–æ–∑–¥–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç
        report_path = output_dir / "inference_summary.txt"
        with open(report_path, 'w') as f:
            f.write("=" * 60 + "\n")
            f.write("XVL Inference Summary Report\n")
            f.write("=" * 60 + "\n\n")
            f.write(f"Total images processed: {total_images}\n")
            f.write(f"Total defects detected: {total_defects}\n")
            f.write(f"Average defects per image: {total_defects/total_images:.2f}\n\n")
            f.write("Defects by class:\n")
            for class_name, count in defect_by_class.items():
                percentage = (count / total_defects * 100) if total_defects > 0 else 0
                f.write(f"  - {class_name}: {count} ({percentage:.1f}%)\n")

        logger.info(f"Summary report saved to: {report_path}")

    def run_web_interface(self, host: str = "127.0.0.1", port: int = 7860):
        """–ó–∞–ø—É—Å–∫ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å—Ç–∞–Ω–æ–≤–∫—É gradio
            import importlib
            spec = importlib.util.find_spec("gradio")
            if spec is None:
                logger.warning("Gradio not installed. Install with: pip install gradio")
                logger.info("You can also use our Hugging Face Space:")
                logger.info("https://huggingface.co/spaces/yourusername/xvl-demo")
                return

            from src.web.app import create_app
            app = create_app(self.predictor)

            logger.info(f"Starting web interface at http://{host}:{port}")
            logger.info("Press Ctrl+C to stop")

            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
            app.launch(
                server_name=host,
                server_port=port,
                share=False  # –î–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            )

        except ImportError:
            logger.error("Web interface dependencies not installed.")
            logger.info("Install with: pip install gradio pillow")
        except Exception as e:
            logger.error(f"Failed to start web interface: {str(e)}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–º–∞–Ω–¥"""
    parser = argparse.ArgumentParser(
        description="XVL: X-Ray Vision Lab - Defect Detection System",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
  python run.py predict --image examples/test_defect.jpg --output results/
  
  # –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–ø–∫–∏
  python run.py predict --dir data/scans/ --output batch_results/
  
  # –î–µ–º–æ-—Ä–µ–∂–∏–º (–≥–µ–Ω–µ—Ä–∞—Ü–∏—è 5 —Ç–µ—Å—Ç–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)
  python run.py demo --count 5
  
  # –ó–∞–ø—É—Å–∫ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
  python run.py web --port 8080
  
  # –ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥
  python run.py predict --image test.jpg --verbose
        """
    )

    subparsers = parser.add_subparsers(dest="command", help="–ö–æ–º–∞–Ω–¥—ã")

    # –ü–∞—Ä—Å–µ—Ä –¥–ª—è predict
    predict_parser = subparsers.add_parser("predict", help="–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–µ—Ñ–µ–∫—Ç–æ–≤")
    predict_group = predict_parser.add_mutually_exclusive_group(required=True)
    predict_group.add_argument("--image", help="–ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é")
    predict_group.add_argument("--dir", help="–ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏")
    predict_parser.add_argument("--output", default="./results",
                               help="–ü–∞–ø–∫–∞ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: ./results)")
    predict_parser.add_argument("--model", help="HF —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –º–æ–¥–µ–ª–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)")
    predict_parser.add_argument("--device", choices=["cpu", "cuda", "auto"],
                               default="auto", help="–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞")

    # –ü–∞—Ä—Å–µ—Ä –¥–ª—è demo
    demo_parser = subparsers.add_parser("demo", help="–î–µ–º–æ-—Ä–µ–∂–∏–º —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –¥–∞–Ω–Ω—ã—Ö")
    demo_parser.add_argument("--count", type=int, default=5,
                            help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    demo_parser.add_argument("--output", default="./demo_results",
                            help="–ü–∞–ø–∫–∞ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–µ–º–æ")

    # –ü–∞—Ä—Å–µ—Ä –¥–ª—è web
    web_parser = subparsers.add_parser("web", help="–ó–∞–ø—É—Å–∫ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞")
    web_parser.add_argument("--host", default="127.0.0.1", help="–•–æ—Å—Ç –¥–ª—è –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–∞")
    web_parser.add_argument("--port", type=int, default=7860, help="–ü–æ—Ä—Ç –¥–ª—è –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–∞")

    # –û–±—â–∏–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã
    parser.add_argument("--verbose", "-v", action="store_true",
                       help="–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥ (debug —Ä–µ–∂–∏–º)")

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return 1

    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º CLI
        cli = XVLCLI()
        cli.setup_environment(verbose=args.verbose)

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–æ–º–∞–Ω–¥—ã
        if args.command == "predict":
            if args.image:
                cli.load_model(args.model, args.device)
                cli.predict_image(args.image, args.output)
            elif args.dir:
                cli.load_model(args.model, args.device)
                cli.predict_directory(args.dir, args.output)

        elif args.command == "demo":
            cli.run_demo(count=args.count, output_dir=args.output)

        elif args.command == "web":
            cli.load_model()  # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
            cli.run_web_interface(host=args.host, port=args.port)

        logger.info("=" * 60)
        logger.info("‚úÖ Operation completed successfully")
        logger.info("=" * 60)

        return 0

    except KeyboardInterrupt:
        logger.warning("\n‚ö†Ô∏è  Process interrupted by user")
        return 130
    except FileNotFoundError as e:
        logger.error(f"‚ùå File error: {e}")
        return 1
    except ModelLoadError as e:
        logger.error(f"‚ùå Model loading failed: {e.message}")
        if e.details:
            logger.debug(f"Details: {e.details}")
        return 1
    except Exception as e:
        logger.error(f"‚ùå Unexpected error: {str(e)}", exc_info=True)
        return 1

if __name__ == "__main__":
    sys.exit(main())