"""
üé® visualizer.py - –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–µ—Ç–µ–∫—Ü–∏–∏ –¥–µ—Ñ–µ–∫—Ç–æ–≤
–ú–æ–¥—É–ª—å –¥–ª—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ bounding boxes, —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á—ë—Ç–æ–≤ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –º–µ—Ç—Ä–∏–∫.
"""

import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle
import matplotlib.patches as patches
from pathlib import Path
from typing import List, Dict, Tuple, Optional, Union
import json
import logging
from dataclasses import dataclass

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = logging.getLogger(__name__)

@dataclass
class VisualizationConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏"""
    # –¶–≤–µ—Ç–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤ (BGR —Ñ–æ—Ä–º–∞—Ç –¥–ª—è OpenCV)
    COLORS = {
        'incomplete_fusion': (0, 165, 255),    # –û—Ä–∞–Ω–∂–µ–≤—ã–π
        'crack': (0, 0, 255),                  # –ö—Ä–∞—Å–Ω—ã–π
        'single_pore': (0, 255, 0),            # –ó–µ–ª—ë–Ω—ã–π
        'cluster_pores': (255, 255, 0),        # –ì–æ–ª—É–±–æ–π
        'empty': (128, 128, 128),              # –°–µ—Ä—ã–π
    }

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ bounding boxes
    BOX_THICKNESS = 2
    TEXT_THICKNESS = 1
    FONT_SCALE = 0.5
    CONFIDENCE_THRESHOLD = 0.3  # –ü–æ—Ä–æ–≥ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤
    PLOT_DPI = 150
    FIGURE_SIZE = (12, 8)

    # –ü—É—Ç–∏
    DEFAULT_OUTPUT_DIR = Path("visualizations")

class DetectionVisualizer:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–µ—Ç–µ–∫—Ü–∏–π"""

    def __init__(self, config: VisualizationConfig = None):
        self.config = config or VisualizationConfig()
        self.output_dir = self.config.DEFAULT_OUTPUT_DIR
        self.output_dir.mkdir(exist_ok=True)

        # –ö—ç—à –¥–ª—è —à—Ä–∏—Ñ—Ç–æ–≤
        self._font_cache = {}

        logger.info(f"DetectionVisualizer initialized. Output dir: {self.output_dir}")

    def _get_color(self, class_name: str) -> Tuple[int, int, int]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ü–≤–µ—Ç –¥–ª—è –∫–ª–∞—Å—Å–∞"""
        return self.config.COLORS.get(class_name, (255, 255, 255))  # –ë–µ–ª—ã–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

    def _get_font(self, scale: float = None):
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞—ë—Ç —à—Ä–∏—Ñ—Ç"""
        scale = scale or self.config.FONT_SCALE
        key = f"scale_{scale}"

        if key not in self._font_cache:
            try:
                # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —à—Ä–∏—Ñ—Ç, –∏–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π
                font = ImageFont.truetype("arial.ttf", int(20 * scale))
            except:
                font = ImageFont.load_default()
            self._font_cache[key] = font

        return self._font_cache[key]

    def draw_detections_pil(
        self,
        image: Union[Image.Image, np.ndarray],
        detections: List[Dict],
        show_confidence: bool = True,
        show_class: bool = True
    ) -> Image.Image:
        """
        –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ—Ç bounding boxes –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º PIL.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏.
        """
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º numpy array –≤ PIL Image –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if isinstance(image, np.ndarray):
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º BGR –≤ RGB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if len(image.shape) == 3 and image.shape[2] == 3:
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(image)
        else:
            pil_image = image.copy()

        draw = ImageDraw.Draw(pil_image)
        font = self._get_font()

        img_width, img_height = pil_image.size

        for detection in detections:
            confidence = detection.get('confidence', 0)

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–∏–∑–∫–æ–≤–µ—Ä–æ—è—Ç–Ω—ã–µ –¥–µ—Ç–µ–∫—Ü–∏–∏
            if confidence < self.config.CONFIDENCE_THRESHOLD:
                continue

            bbox = detection['bbox']  # [x1, y1, x2, y2]
            class_name = detection.get('class', 'unknown')

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if all(0 <= coord <= 1 for coord in bbox):
                x1 = bbox[0] * img_width
                y1 = bbox[1] * img_height
                x2 = bbox[2] * img_width
                y2 = bbox[3] * img_height
            else:
                x1, y1, x2, y2 = bbox

            # –ü–æ–ª—É—á–∞–µ–º —Ü–≤–µ—Ç –¥–ª—è –∫–ª–∞—Å—Å–∞
            color = self._get_color(class_name)
            color_rgb = color[::-1]  # BGR to RGB

            # –†–∏—Å—É–µ–º bounding box
            draw.rectangle(
                [x1, y1, x2, y2],
                outline=color_rgb,
                width=self.config.BOX_THICKNESS
            )

            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞
            text_parts = []
            if show_class:
                text_parts.append(class_name)
            if show_confidence:
                text_parts.append(f"{confidence:.1%}")

            if text_parts:
                text = " ".join(text_parts)

                # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–∞
                try:
                    bbox_text = draw.textbbox((0, 0), text, font=font)
                    text_width = bbox_text[2] - bbox_text[0]
                    text_height = bbox_text[3] - bbox_text[1]
                except:
                    text_width = len(text) * 10
                    text_height = 20

                # –†–∏—Å—É–µ–º —Ñ–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞
                text_bg = [
                    x1,
                    max(y1 - text_height - 5, 0),
                    x1 + text_width + 10,
                    max(y1, text_height + 5)
                ]

                draw.rectangle(text_bg, fill=color_rgb)

                # –†–∏—Å—É–µ–º —Ç–µ–∫—Å—Ç
                draw.text(
                    (x1 + 5, max(y1 - text_height - 2, 2)),
                    text,
                    fill=(255, 255, 255),  # –ë–µ–ª—ã–π —Ç–µ–∫—Å—Ç
                    font=font
                )

        return pil_image

    def draw_detections_cv2(
        self,
        image: np.ndarray,
        detections: List[Dict],
        show_confidence: bool = True,
        show_class: bool = True
    ) -> np.ndarray:
        """
        –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ—Ç bounding boxes —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º OpenCV.
        –ë—ã—Å—Ç—Ä–µ–µ —á–µ–º PIL, –Ω–æ –º–µ–Ω–µ–µ –≥–∏–±–∫–æ –≤ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞.
        """
        img_copy = image.copy()
        img_height, img_width = img_copy.shape[:2]

        for detection in detections:
            confidence = detection.get('confidence', 0)

            if confidence < self.config.CONFIDENCE_THRESHOLD:
                continue

            bbox = detection['bbox']
            class_name = detection.get('class', 'unknown')

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if all(0 <= coord <= 1 for coord in bbox):
                x1 = int(bbox[0] * img_width)
                y1 = int(bbox[1] * img_height)
                x2 = int(bbox[2] * img_width)
                y2 = int(bbox[3] * img_height)
            else:
                x1, y1, x2, y2 = map(int, bbox)

            # –ü–æ–ª—É—á–∞–µ–º —Ü–≤–µ—Ç
            color = self._get_color(class_name)

            # –†–∏—Å—É–µ–º bounding box
            cv2.rectangle(
                img_copy,
                (x1, y1),
                (x2, y2),
                color,
                self.config.BOX_THICKNESS
            )

            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞
            text_parts = []
            if show_class:
                text_parts.append(class_name.replace('_', ' '))
            if show_confidence:
                text_parts.append(f"{confidence:.0%}")

            if text_parts:
                text = " ".join(text_parts)

                # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–∞
                (text_width, text_height), baseline = cv2.getTextSize(
                    text,
                    cv2.FONT_HERSHEY_SIMPLEX,
                    self.config.FONT_SCALE,
                    self.config.TEXT_THICKNESS
                )

                # –†–∏—Å—É–µ–º —Ñ–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞
                cv2.rectangle(
                    img_copy,
                    (x1, max(y1 - text_height - 10, 0)),
                    (x1 + text_width + 10, y1),
                    color,
                    -1  # –ó–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–π –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
                )

                # –†–∏—Å—É–µ–º —Ç–µ–∫—Å—Ç
                cv2.putText(
                    img_copy,
                    text,
                    (x1 + 5, y1 - 5),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    self.config.FONT_SCALE,
                    (255, 255, 255),  # –ë–µ–ª—ã–π —Ç–µ–∫—Å—Ç
                    self.config.TEXT_THICKNESS,
                    cv2.LINE_AA
                )

        return img_copy

    def create_detection_report(
        self,
        image_path: Union[str, Path],
        detections: List[Dict],
        output_path: Optional[Union[str, Path]] = None,
        save_json: bool = True
    ) -> Dict:
        """
        –°–æ–∑–¥–∞–µ—Ç –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –¥–µ—Ç–µ–∫—Ü–∏—è–º –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏ –ø—É—Ç—è–º–∏ –∫ —Ñ–∞–π–ª–∞–º.
        """
        image_path = Path(image_path)
        if not image_path.exists():
            raise FileNotFoundError(f"Image not found: {image_path}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        img = cv2.imread(str(image_path))
        if img is None:
            raise ValueError(f"Cannot load image: {image_path}")

        # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω—ã–µ –ø—É—Ç–∏
        if output_path is None:
            timestamp = Path(image_path).stem
            output_path = self.output_dir / f"report_{timestamp}"
        output_path = Path(output_path)
        output_path.mkdir(parents=True, exist_ok=True)

        # –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–µ—Ç–µ–∫—Ü–∏–∏
        img_with_boxes = self.draw_detections_cv2(img, detections)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
        vis_path = output_path / f"{image_path.stem}_detected.jpg"
        cv2.imwrite(str(vis_path), img_with_boxes)

        # –°–æ–∑–¥–∞–µ–º JSON —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        metadata = {
            "image": str(image_path),
            "detections_count": len(detections),
            "detections": detections,
            "visualization": str(vis_path),
            "statistics": self._calculate_statistics(detections)
        }

        if save_json:
            json_path = output_path / f"{image_path.stem}_detections.json"
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            metadata["json_report"] = str(json_path)

        # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫ —Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∫–ª–∞—Å—Å–æ–≤
        plot_path = self._create_class_distribution_plot(detections, output_path)
        metadata["class_distribution_plot"] = str(plot_path)

        logger.info(f"Report created: {output_path}")
        logger.info(f"  - Detections: {len(detections)}")
        logger.info(f"  - Visualization: {vis_path.name}")
        logger.info(f"  - Statistics: {metadata['statistics']}")

        return metadata

    def create_comparison_grid(
        self,
        images_data: List[Dict],  # –°–ø–∏—Å–æ–∫ {'path': Path, 'detections': List}
        output_path: Union[str, Path],
        grid_size: Tuple[int, int] = (3, 3),
        titles: Optional[List[str]] = None
    ) -> Path:
        """
        –°–æ–∑–¥–∞–µ—Ç grid –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –¥–µ—Ç–µ–∫—Ü–∏—è–º–∏.
        –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –¥–µ–º–æ-–æ—Ç—á–µ—Ç–æ–≤.
        """
        output_path = Path(output_path)

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ä–∞–∑–º–µ—Ä—É grid
        max_images = grid_size[0] * grid_size[1]
        images_data = images_data[:max_images]

        fig, axes = plt.subplots(
            grid_size[0],
            grid_size[1],
            figsize=(grid_size[1] * 4, grid_size[0] * 3)
        )
        axes = axes.flatten() if hasattr(axes, 'flatten') else [axes]

        for idx, (ax, img_data) in enumerate(zip(axes, images_data)):
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            img_path = Path(img_data['path'])
            detections = img_data.get('detections', [])

            img = cv2.imread(str(img_path))
            if img is not None:
                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                img_with_boxes = self.draw_detections_cv2(img_rgb, detections)

                ax.imshow(img_with_boxes)

                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                title_parts = [img_path.stem]
                if detections:
                    title_parts.append(f"({len(detections)} def)")
                if titles and idx < len(titles):
                    title_parts.append(titles[idx])

                ax.set_title(" | ".join(title_parts), fontsize=10)
                ax.axis('off')

                # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –¥–µ—Ñ–µ–∫—Ç–æ–≤
                if detections:
                    ax.text(
                        0.02, 0.98,
                        f"Detections: {len(detections)}",
                        transform=ax.transAxes,
                        fontsize=9,
                        verticalalignment='top',
                        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5)
                    )
            else:
                ax.text(0.5, 0.5, f"Failed to load\n{img_path.name}",
                       ha='center', va='center', transform=ax.transAxes)
                ax.axis('off')

        # –°–∫—Ä—ã–≤–∞–µ–º –ø—É—Å—Ç—ã–µ subplots
        for idx in range(len(images_data), len(axes)):
            axes[idx].axis('off')

        plt.tight_layout()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º grid
        grid_path = output_path / "detection_grid.jpg"
        plt.savefig(grid_path, dpi=self.config.PLOT_DPI, bbox_inches='tight')
        plt.close()

        logger.info(f"Comparison grid created: {grid_path}")
        return grid_path

    def _calculate_statistics(self, detections: List[Dict]) -> Dict:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –¥–µ—Ç–µ–∫—Ü–∏—è–º"""
        if not detections:
            return {"total": 0, "by_class": {}, "avg_confidence": 0}

        stats = {
            "total": len(detections),
            "by_class": {},
            "confidences": [],
            "avg_confidence": 0
        }

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–ª–∞—Å—Å–∞–º
        for det in detections:
            class_name = det.get('class', 'unknown')
            confidence = det.get('confidence', 0)

            if class_name not in stats['by_class']:
                stats['by_class'][class_name] = {
                    'count': 0,
                    'avg_confidence': 0,
                    'confidences': []
                }

            stats['by_class'][class_name]['count'] += 1
            stats['by_class'][class_name]['confidences'].append(confidence)
            stats['confidences'].append(confidence)

        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        if stats['confidences']:
            stats['avg_confidence'] = np.mean(stats['confidences'])

        for class_name, class_stats in stats['by_class'].items():
            if class_stats['confidences']:
                class_stats['avg_confidence'] = np.mean(class_stats['confidences'])
            del class_stats['confidences']  # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫

        return stats

    def _create_class_distribution_plot(
        self,
        detections: List[Dict],
        output_dir: Path
    ) -> Path:
        """–°–æ–∑–¥–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤"""
        if not detections:
            return None

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ –∫–ª–∞—Å—Å–∞–º
        class_counts = {}
        confidences_by_class = {}

        for det in detections:
            class_name = det.get('class', 'unknown')
            confidence = det.get('confidence', 0)

            class_counts[class_name] = class_counts.get(class_name, 0) + 1
            if class_name not in confidences_by_class:
                confidences_by_class[class_name] = []
            confidences_by_class[class_name].append(confidence)

        # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

        # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
        classes = list(class_counts.keys())
        counts = list(class_counts.values())
        colors = [self._get_color(cls) for cls in classes]
        colors_rgb = [(c[2]/255, c[1]/255, c[0]/255) for c in colors]  # BGR to RGB

        bars = ax1.bar(classes, counts, color=colors_rgb, edgecolor='black')
        ax1.set_title('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ç–µ–∫—Ü–∏–π –ø–æ –∫–ª–∞—Å—Å–∞–º', fontsize=12)
        ax1.set_xlabel('–ö–ª–∞—Å—Å –¥–µ—Ñ–µ–∫—Ç–∞')
        ax1.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
        ax1.tick_params(axis='x', rotation=45)

        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
        for bar in bars:
            height = bar.get_height()
            ax1.annotate(f'{height}',
                        xy=(bar.get_x() + bar.get_width() / 2, height),
                        xytext=(0, 3),
                        textcoords="offset points",
                        ha='center', va='bottom')

        # Box plot —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–µ–π
        confidence_data = []
        labels = []
        for class_name in classes:
            if class_name in confidences_by_class and confidences_by_class[class_name]:
                confidence_data.append(confidences_by_class[class_name])
                labels.append(f"{class_name}\n(n={len(confidences_by_class[class_name])})")

        if confidence_data:
            bp = ax2.boxplot(confidence_data, labels=labels, patch_artist=True)

            # –†–∞—Å–∫—Ä–∞—à–∏–≤–∞–µ–º box plots
            for patch, color in zip(bp['boxes'], colors_rgb):
                patch.set_facecolor(color)

            ax2.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–µ–π –ø–æ –∫–ª–∞—Å—Å–∞–º', fontsize=12)
            ax2.set_ylabel('–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å')
            ax2.grid(True, alpha=0.3)

        plt.tight_layout()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫
        plot_path = output_dir / "class_distribution.jpg"
        plt.savefig(plot_path, dpi=self.config.PLOT_DPI, bbox_inches='tight')
        plt.close()

        return plot_path

# –§–∞–±—Ä–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
def create_visualizer(config: VisualizationConfig = None) -> DetectionVisualizer:
    """–°–æ–∑–¥–∞–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä"""
    return DetectionVisualizer(config)

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
    import tempfile

    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    test_image = np.zeros((400, 600, 3), dtype=np.uint8)
    test_image[:] = (100, 100, 100)  # –°–µ—Ä—ã–π —Ñ–æ–Ω

    test_detections = [
        {
            'bbox': [100, 100, 200, 200],
            'confidence': 0.85,
            'class': 'crack'
        },
        {
            'bbox': [300, 150, 400, 250],
            'confidence': 0.72,
            'class': 'single_pore'
        },
        {
            'bbox': [200, 300, 350, 380],
            'confidence': 0.45,
            'class': 'incomplete_fusion'
        }
    ]

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä
    visualizer = DetectionVisualizer()

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã
    print("Testing visualization methods...")

    # –ú–µ—Ç–æ–¥ OpenCV
    result_cv2 = visualizer.draw_detections_cv2(test_image, test_detections)

    # –ú–µ—Ç–æ–¥ PIL
    pil_image = Image.fromarray(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))
    result_pil = visualizer.draw_detections_pil(pil_image, test_detections)

    # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç
    with tempfile.TemporaryDirectory() as tmpdir:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        test_path = Path(tmpdir) / "test_image.jpg"
        cv2.imwrite(str(test_path), test_image)

        # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç
        report = visualizer.create_detection_report(
            test_path,
            test_detections,
            output_path=Path(tmpdir) / "report"
        )

        print(f"Report created at: {report['visualization']}")
        print(f"Statistics: {report['statistics']}")

    print("Visualizer test completed successfully!")